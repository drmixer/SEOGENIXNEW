import { createClient, SupabaseClient } from "https://esm.sh/@supabase/supabase-js@2";

// --- SHARED: CORS Headers ---
const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

// --- SHARED: Response Helpers ---
function createErrorResponse(message: string, status = 500, details?: any) {
  return new Response(JSON.stringify({
    success: false,
    error: {
      message,
      details: details || undefined,
    }
  }), {
    status,
    headers: { ...corsHeaders, "Content-Type": "application/json" },
  });
}

function createSuccessResponse(data: object, status = 200) {
  return new Response(JSON.stringify({
    success: true,
    data,
  }), {
    status,
    headers: { ...corsHeaders, "Content-Type": "application/json" },
  });
}

// --- SHARED: Service Handler ---
async function serviceHandler(req: Request, toolLogic: Function) {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders });
  }
  try {
    const supabaseAdminClient = createClient(
      Deno.env.get("SUPABASE_URL")!,
      Deno.env.get("SUPABASE_SERVICE_ROLE_KEY")!
    );

    const authHeader = req.headers.get('Authorization');
    if (!authHeader) {
      return createErrorResponse('Missing Authorization header', 401);
    }

    const supabaseClient = createClient(
      Deno.env.get("SUPABASE_URL")!,
      Deno.env.get("SUPABASE_ANON_KEY")!,
      { global: { headers: { Authorization: authHeader } } }
    );

    const { data: { user } } = await supabaseClient.auth.getUser();
    if (!user) {
        return createErrorResponse('Invalid or expired token', 401);
    }

    return await toolLogic(req, { user, supabaseClient, supabaseAdminClient });

  } catch (err) {
    const errorMessage = err instanceof Error ? err.message : 'An unknown server error occurred.';
    console.error(`[ServiceHandler Error]`, err);
    return createErrorResponse(errorMessage, 500, err instanceof Error ? err.stack : undefined);
  }
}

// --- SHARED: Database Logging Helpers ---
async function logToolRun(supabase: SupabaseClient, projectId: string, toolName: string, inputPayload: object) {
  if (!projectId) throw new Error("logToolRun error: projectId is required.");
  const { data, error } = await supabase.from("tool_runs").insert({ project_id: projectId, tool_name: toolName, input_payload: inputPayload, status: "running" }).select("id").single();
  if (error) {
    console.error("Error logging tool run:", error);
    throw new Error(`Failed to log tool run. Supabase error: ${error.message}`);
  }
  if (!data || !data.id) {
    console.error("No data or data.id returned from tool_runs insert.");
    throw new Error("Failed to log tool run: No data returned after insert.");
  }
  return data.id;
}

async function updateToolRun(supabase: SupabaseClient, runId: string, status: string, outputPayload: object | null, errorMessage: string | null) {
  if (!runId) {
    console.error("updateToolRun error: runId is required.");
    return;
  }
  const update = { status, completed_at: new Date().toISOString(), output_payload: errorMessage ? { error: errorMessage } : outputPayload || null, error_message: errorMessage || null };
  const { error } = await supabase.from("tool_runs").update(update).eq("id", runId);
  if (error) console.error(`Error updating tool run ID ${runId}:`, error);
}

// --- SHARED: Robust AI Call Function ---
async function callGeminiWithRetry(prompt: string, apiKey: string) {
  let attempts = 0;
  const maxAttempts = 4;
  let delay = 1000;

  while (attempts < maxAttempts) {
    try {
      const geminiResponse = await fetch(
        `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${apiKey}`,
        {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            contents: [{ parts: [{ text: prompt }] }],
            generationConfig: {
              temperature: 0.2,
              maxOutputTokens: 4096,
            },
          }),
        }
      );

      if (!geminiResponse.ok) {
        if (geminiResponse.status === 429 || geminiResponse.status === 503) {
            const errorText = await geminiResponse.text();
            throw new Error(`Retryable Gemini API error: ${geminiResponse.status} ${errorText}`);
        }
        const errorText = await geminiResponse.text();
        console.error('Gemini API error:', geminiResponse.status, errorText);
        throw new Error(`Gemini API failed with status ${geminiResponse.status}: ${errorText}`);
      }

      const geminiData = await geminiResponse.json();
      const candidate = geminiData.candidates?.[0];
      if (!candidate) throw new Error('No content generated by Gemini API');

      const responseText = candidate.content?.parts?.[0]?.text;
      if (!responseText) throw new Error('Invalid response structure from Gemini API');

      const jsonMatch = responseText.match(/```json\s*([\s\S]*?)\s*```/);
      if (!jsonMatch || !jsonMatch[1]) {
        throw new Error('Failed to extract JSON from AI response.');
      }
      return JSON.parse(jsonMatch[1]);

    } catch (error) {
       if (error.message.includes("Retryable")) {
            attempts++;
            await new Promise(resolve => setTimeout(resolve, delay));
            delay *= 2;
       } else {
           throw error;
       }
    }
  }
  throw new Error("The AI model is currently overloaded after multiple retries.");
}


// --- TOOL-SPECIFIC: Type Definitions ---
interface CitationRequest {
    projectId: string;
    domain: string;
    keywords: string[];
}

interface RedditPost {
    kind: string;
    data: {
        title: string;
        selftext: string;
        url: string;
        permalink: string;
        created_utc: number;
        subreddit_name_prefixed: string;
    };
}

// --- TOOL-SPECIFIC: AI Prompt Engineering ---
const getAnalysisPrompt = (posts: RedditPost[], domain: string): string => {
    const jsonSchema = `{
      "citations": [{
          "source": "string (e.g., 'r/technology')",
          "url": "string (The full URL to the Reddit post)",
          "snippet": "string (A 1-2 sentence quote of the mention)",
          "date": "string (ISO 8601 timestamp)",
          "type": "reddit",
          "confidence_score": "number (0-100)"
      }]
    }`;

    return `You are an expert Data Extraction Bot. Analyze the provided Reddit posts to find mentions of a specific domain.
    - **Domain to track:** ${domain}
    - **Raw Reddit Search Results:** ${JSON.stringify(posts.slice(0, 25), null, 2)}

    **Instructions:**
    1. Identify posts that contain a genuine mention of the tracked domain.
    2. For each genuine citation, extract the required information.
    3. The 'url' should be the full Reddit URL (https://www.reddit.com + permalink).

    **CRITICAL: You MUST provide your response in a single, valid JSON object enclosed in a \`\`\`json markdown block.**
    The JSON object must follow this exact schema:
    \`\`\`json
    ${jsonSchema}
    \`\`\`
    If no relevant citations are found, return an empty "citations" array.
    `;
};


// --- TOOL-SPECIFIC: Main Logic ---
const citationTrackerToolLogic = async (req: Request, { user, supabaseClient, supabaseAdminClient }: { user: any, supabaseClient: SupabaseClient, supabaseAdminClient: SupabaseClient }) => {
  let runId: string | null = null;
  try {
    const { projectId, domain, keywords }: CitationRequest = await req.json();

    if (!projectId || !domain || !keywords || keywords.length === 0) {
      throw new Error('`projectId`, `domain`, and `keywords` are required.');
    }
    console.log(`Citation tracker request for project ${projectId}`);

    const { data: project, error: projectError } = await supabaseClient.from('projects').select('id').eq('id', projectId).single();
    if (projectError || !project) {
        throw new Error(`Access denied or project not found for id: ${projectId}`);
    }

    runId = await logToolRun(supabaseAdminClient, projectId, 'citation-tracker', { domain, keywords });
    console.log(`Tool run logged with ID: ${runId}`);

    const clientId = Deno.env.get('REDDIT_CLIENT_ID');
    const clientSecret = Deno.env.get('REDDIT_CLIENT_SECRET');
    const userAgent = Deno.env.get('REDDIT_USER_AGENT');
    if (!clientId || !clientSecret || !userAgent) throw new Error('Reddit API credentials are not configured.');

    const tokenResponse = await fetch('https://www.reddit.com/api/v1/access_token', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/x-www-form-urlencoded',
            'Authorization': `Basic ${btoa(`${clientId}:${clientSecret}`)}`,
            'User-Agent': userAgent,
        },
        body: 'grant_type=client_credentials',
    });
    if (!tokenResponse.ok) throw new Error(`Failed to get Reddit access token: ${tokenResponse.statusText}`);
    const tokenData = await tokenResponse.json();

    const searchQuery = `${domain} OR "${keywords.join('" OR "')}"`;
    const searchUrl = `https://oauth.reddit.com/search?q=${encodeURIComponent(searchQuery)}&sort=new&limit=50`;
    const searchResponse = await fetch(searchUrl, {
        headers: { 'Authorization': `Bearer ${tokenData.access_token}`, 'User-Agent': userAgent }
    });
    if (!searchResponse.ok) throw new Error(`Reddit API search failed: ${searchResponse.statusText}`);
    const searchData = await searchResponse.json();
    const posts: RedditPost[] = searchData.data.children;
    console.log(`Found ${posts.length} potential posts from Reddit.`);

    if (posts.length === 0) {
        const output = { citations: [] };
        await updateToolRun(supabaseAdminClient, runId, 'completed', output, null);
        return createSuccessResponse({ runId, ...output });
    }

    const geminiApiKey = Deno.env.get('GEMINI_API_KEY');
    if (!geminiApiKey) throw new Error('Gemini API key not configured');

    const prompt = getAnalysisPrompt(posts, domain);
    const finalData = await callGeminiWithRetry(prompt, geminiApiKey);

    if (!finalData.citations) {
      throw new Error('Generated data missing required "citations" field.');
    }

    await updateToolRun(supabaseAdminClient, runId, 'completed', finalData, null);
    console.log('Citation tracking complete.');
    return createSuccessResponse({ runId, ...finalData });

  } catch (err) {
    const errorMessage = err instanceof Error ? err.message : 'An unknown error occurred.';
    console.error('Citation tracker error:', err);
    if (runId) {
      await updateToolRun(supabaseAdminClient, runId, 'error', null, errorMessage);
    }
    return createErrorResponse(errorMessage, 500, err instanceof Error ? err.stack : undefined);
  }
};

// --- Server ---
Deno.serve((req) => serviceHandler(req, citationTrackerToolLogic));
